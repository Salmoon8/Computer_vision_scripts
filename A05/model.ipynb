{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "with zipfile.ZipFile(\"archive.zip\") as facezip:\n",
    "    for filename in facezip.namelist():\n",
    "        if not filename.endswith(\".pgm\") and not filename.endswith(\".jpeg\"):\n",
    "            continue # not a face picture\n",
    "        with facezip.open(filename) as image:\n",
    "            # If we extracted files from zip, we can use cv2.imread(filename) instead\n",
    "            data[filename] = cv2.imdecode(np.frombuffer(image.read(), np.uint8), cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(img):\n",
    "    face_classifier = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "    # The detectMultiScale() method is used to identify faces of different sizes in the input image.\n",
    "    face = face_classifier.detectMultiScale(\n",
    "    img, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n",
    "    )\n",
    "# finally, the minSize parameter sets the minimum size of the object to be detected.\n",
    "# The model will ignore faces that are smaller than the minimum size specified.\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(faces):\n",
    "    # Convert the list of face images into a 2D array\n",
    "    X = np.array(faces).reshape(len(faces), -1).astype(np.float64)\n",
    "\n",
    "    # Compute the mean face and subtract it from each face image\n",
    "    mean_face = np.mean(X, axis=0)\n",
    "    X -= mean_face\n",
    "\n",
    "    # Compute the covariance matrix of the face images\n",
    "    cov = np.cov(X.T)\n",
    "\n",
    "    # Compute the eigenvectors and eigenvalues of the covariance matrix\n",
    "    eigvals, eigvecs = np.linalg.eig(cov)\n",
    "\n",
    "    # Sort the eigenvectors by eigenvalue in descending order\n",
    "    sort_indices = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[sort_indices]\n",
    "    eigvecs = eigvecs[:, sort_indices]\n",
    "\n",
    "    # Project the face images onto the lower-dimensional space\n",
    "    X_pca = np.dot(X, eigvecs)\n",
    "\n",
    "    return mean_face, eigvecs, X_pca\n",
    "\n",
    "def perform_pca_faster(faces):\n",
    "    # Convert the list of face images into a 2D array\n",
    "    X = np.array(faces).reshape(len((faces)), -1).astype(np.float64)\n",
    "    # Compute the mean face and subtract it from each face image\n",
    "    mean_face = np.mean(X, axis=0)\n",
    "    X -= mean_face\n",
    "    # Compute the SVD of the centered face images\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    print(Vt.shape)\n",
    "\n",
    "    # Project the face images onto the lower-dimensional space\n",
    "    X_pca = np.dot(X, Vt.T)\n",
    "\n",
    "    return mean_face, Vt, X_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_recognition_model_grid_search(X_pca , labels):\n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'n_neighbors': [1, 3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "\n",
    "    # Create a k-NN classifier object\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Create a GridSearchCV object to search over the parameter grid\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "    # Fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_pca, labels)\n",
    "\n",
    "    # Print the best hyperparameters found\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "    # Train a k-NN classifier using the best hyperparameters found\n",
    "    best_knn = KNeighborsClassifier(**grid_search.best_params_)\n",
    "    best_knn.fit(X_pca, labels)\n",
    "    return best_knn\n",
    "\n",
    "def knn_recognition_model(X_pca, labels):\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf.fit(X_pca, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract faces from the data set\n",
    "faces = []\n",
    "labels = []\n",
    "for filename, img in data.items():\n",
    "    print(filename.split(\"/\")[0])\n",
    "    detected_faces = face_detection(img)\n",
    "    for (x, y, w, h) in detected_faces:\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "        resized_face = cv2.resize(face_img, (100, 100))\n",
    "        faces.append(resized_face)\n",
    "        labels.append(filename.split(\"/\")[0])\n",
    "\n",
    "# Convert the list of faces to a numpy array\n",
    "faces = np.array(faces)\n",
    "print(len(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(353, 353)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_face, eigvecs, X_pca = perform_pca_faster(faces)\n",
    "\n",
    "X_pca.shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X_pca, test_X_pca,train_labels, test_labels = train_test_split(list(X_pca), list(labels), test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_pca),len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = knn_recognition_model_grid_search(train_X_pca, train_labels)\n",
    "\n",
    "y_pred = knn_model.predict(test_X_pca)\n",
    "\n",
    "accuracy = knn_model.score(train_X_pca, train_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy*100 , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Accuracy: 19.06474820143885 %\n"
     ]
    }
   ],
   "source": [
    "knn_model = knn_recognition_model_grid_search(train_X_pca, train_labels)\n",
    "\n",
    "y_pred = knn_model.predict(train_X_pca)\n",
    "\n",
    "accuracy = knn_model.score(train_X_pca, train_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy*100 , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svm_recognition_model(X_train, y_train):\n",
    "    # Define parameter grid to search over\n",
    "    param_grid = {'C': [0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "    # Create a SVM classifier\n",
    "    svm_clf = SVC()\n",
    "\n",
    "    # Use GridSearchCV to find the best hyperparameters\n",
    "    svm_grid = GridSearchCV(svm_clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters and the best accuracy\n",
    "    print(\"Best hyperparameters:\", svm_grid.best_params_)\n",
    "    print(\"Accuracy:\", svm_grid.best_score_ *100 , '%')\n",
    "\n",
    "    # Return the trained classifier\n",
    "    return svm_grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit PCA on the training data\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(train_X_pca)\n",
    "\n",
    "# Transform the test data using the fitted PCA object\n",
    "transformed_test_X = pca.transform(test_X_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Salman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Accuracy: 68.95238095238095 %\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm_recognition_model(test_X_pca, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
